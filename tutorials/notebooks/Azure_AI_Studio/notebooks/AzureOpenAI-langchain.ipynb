{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Use your deployed model from a notebook using Langchain"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Background\n",
        "This tutorial is designed to give you the basics of using langchain to work with Large Language Models (LLMs) for document summarization and basic chat bot functionality. You could take what we have here to build a front end application using something like streamlit, or other further iterations."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install Packages"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install langchain"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Libraries"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain.schema import HumanMessage\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.document_loaders import WebBaseLoader\n",
        "from langchain.chat_models import AzureChatOpenAI\n",
        "from langchain.embeddings import AzureOpenAIEmbeddings\n"
      ],
      "outputs": [],
      "execution_count": 54,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1699910512197
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Try loading in your deployed model and running a simple prompt"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = AzureChatOpenAI(\n",
        "    openai_api_version=\"2023-05-15\",\n",
        "    #openai_api_base=\"https://nih-openai-poc.azure.openai.com/openai/deployments/nih-openai-poc-35-0301\",\n",
        "    azure_endpoint = \"https://nih-openai-poc.openai.azure.com/openai/deployments/nih-openai-poc-35-0301/chat/completions?api-version=2023-07-01-preview\",\n",
        "    openai_api_key=\"01f0a2f985f44fe182f226a8b33aa03a\"\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 39,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1699909844481
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the prompt against the LLM"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "message = HumanMessage(\n",
        "    content=\"Translate this sentence from English to French: Why all the hype about Generative AI?\"\n",
        ")\n",
        "llm([message])"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 45,
          "data": {
            "text/plain": "AIMessage(content=\"Pourquoi tout ce battage médiatique autour de l'IA générative ?\")"
          },
          "metadata": {}
        }
      ],
      "execution_count": 45,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1699909895704
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Use the LLM to summarize a scientific document"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's load in a scientific document to run a query against. Read more about document loaders from langchain [here](https://python.langchain.com/docs/modules/data_connection/document_loaders/pdf). Note that we are both loading, and splitting our document. You can read more about the default document chunking/splitting procedures [here](https://python.langchain.com/docs/modules/data_connection/document_transformers/#get-started-with-text-splitters)."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loader = WebBaseLoader(\"https://pubmed.ncbi.nlm.nih.gov/37883540/\")\n",
        "pages = loader.load_and_split()"
      ],
      "outputs": [],
      "execution_count": 47,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1699909908495
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define that we want to use [stuffing](https://python.langchain.com/docs/modules/chains/document/stuff) to summarize the document."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chain = load_summarize_chain(model, chain_type=\"stuff\")\n",
        "\n",
        "chain.run(pages)\n",
        "\n"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 49,
          "data": {
            "text/plain": "'A study published in Science has provided evidence of menopause in wild chimpanzees, suggesting that post-reproductive life spans exist not only in humans but in some other mammals as well. The study found that post-reproductive representation was 0.195, meaning that a female who reached adulthood could expect to live about one-fifth of her adult life in a post-reproductive state, around half as long as human hunter-gatherers. Post-reproductive females exhibited hormonal signatures of menopause, including sharply increasing gonadotropins after age 50. The study suggests that post-reproductive life spans in wild chimpanzees may be an evolved species-typical trait and has implications for our understanding of the evolution of post-reproductive life spans.'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 49,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1699909918382
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next step is to create a chat bot via embeddings. That's in the next tutorial"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
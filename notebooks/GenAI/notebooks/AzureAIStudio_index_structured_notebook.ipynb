{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "403555d2-4703-4bec-94ec-9d17ec656d62",
   "metadata": {},
   "source": [
    "# Indexing Delimited Files on Azure AI Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e421b4fd",
   "metadata": {},
   "source": [
    "## Overview\n",
    "LLMs work best when querying vector databases (DBs). In a few of our tutorials in this repo, we have created vector DBs from unstructured data like PDF documents. Here, we create a vector DB from structured data, which is technically complex and requires additional steps. Here we will vectorize (embed) a csv file, index our DB using Azure AI Search, and then query our vector DB using a GPT model deployed within Azure AI Studio."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fe0439",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "We assume you have access to Azure AI Studio and Azure AI Search Service and have already deployed an LLM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5376ef",
   "metadata": {},
   "source": [
    "## Learning objectives\n",
    "\n",
    "This tutorial will cover the following topics:\n",
    "+ Introduce embeddings from structured data\n",
    "+ Create Azure AI Search index from command line\n",
    "+ Query Azure AI Search index from command line using LLMs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd8094c",
   "metadata": {},
   "source": [
    "## Get started"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efcb4f8-f3a1-4ea8-b826-012ceb733f4a",
   "metadata": {},
   "source": [
    "### Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb68924-26c9-4e6e-9880-2ea371c8d188",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -U \"langchain\" \"openai\" \"langchain-openai\" \"langchain-community\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5292c962-637e-4169-ad77-2e62da44596f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install azure-search-documents --pre --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687d3dea-ea4c-4eea-8e5a-cff78c0340de",
   "metadata": {},
   "source": [
    "### Import CSV data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4687557-c31a-4b6c-a17a-8628e46ad7a3",
   "metadata": {},
   "source": [
    "For this tutorial we are using a Kaggle dataset about data scientist salaries from 2023. This dataset can be downloaded from [here](https://www.kaggle.com/datasets/henryshan/2023-data-scientists-salary)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed34bedc-6339-4991-96b3-e9a2ac62b1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "# reading the csv file using read_csv\n",
    "# storing the data frame in variable called df\n",
    "df = pd.read_csv('ds_salaries.csv')\n",
    " \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c03a9b-9719-45e3-9bca-31fd310eb916",
   "metadata": {},
   "source": [
    "Add an ID to each row of your data this will be the key in our Index. If you choose to use your own data make sure to clean up any trailing whitespaces or punctuation. Your headers should not have any spaces between the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41c5439-4b14-41a3-aaf4-c6f704c9f232",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ID'] = np.arange(df.shape[0]).astype(str)\n",
    "\n",
    "#making the entire dataset into strings\n",
    "df= df.astype(str)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db997a43-4195-487f-b023-795d361db993",
   "metadata": {},
   "source": [
    "#### Optional: Adding embeddings to our data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a03ce7-87a4-4e94-acd1-cd01fa3cfa81",
   "metadata": {},
   "source": [
    "If you want to add embeddings to your data you can run the code below! Embeddings will help our vector store (Azure AI Search) to retrieve relevant information based on the query or question you have supplied the model. Here we use the embedding **text-embedding-ada-002** to convert our data into numerical values which represents how similar each word is to another in your data. Embedding are usually used for dense data so if you have any columns in your dataset that contains sentences of text its recommended to add embeddings. Although the dataset we are using doesn't have that for this example we will be adding embeddings for the `job_title` column and add them to a new column called and `job_title_vector`.\n",
    "\n",
    "**If you don't want to add embeddings you can skip this code cell and run the [next one](#csv2json).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87181df6-c8d5-4498-ac6b-faa86631125e",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"<Your Azure Endpoint>\"\n",
    "os.environ[\"AZURE_OPENAI_KEY\"] = \"<Your Azure AI Key>\"\n",
    "\n",
    "#create embeddings functions to apply to a given column\n",
    "from openai import AzureOpenAI\n",
    "    \n",
    "client = AzureOpenAI(\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_KEY\"),  \n",
    "    api_version=\"2023-05-15\",\n",
    "    azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "    )\n",
    "\n",
    "def generate_embeddings(text, model=\"text-embedding-ada-002\"):\n",
    "    return client.embeddings.create(input = [text], model=model).data[0].embedding\n",
    "\n",
    "#adding embeddings for job title to get more accurate search results\n",
    "df['job_title_vector'] = df['job_title'].apply(lambda x : generate_embeddings (x)) # model should be set to the deployment name you chose when you deployed the text-embedding-ada-002 (Version 2) model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b1da1e-4eda-47c3-a8d4-d04df80b0476",
   "metadata": {},
   "source": [
    "<a id='csv2json'> Now we will convert our dataframe into JSON format. </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4c4453-d958-49ad-9b72-34a829ac0437",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_json = df.to_json(orient=\"records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a532eacf-ff14-44fc-b703-844f83c846bd",
   "metadata": {},
   "source": [
    "### Connect to our Azure Open AI Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bfd4382-8809-4bb8-8940-68d81f8fba44",
   "metadata": {},
   "source": [
    "Here we are setting the keys and endpoint to our OpenAI models as environmental variables which will help us connect to our LLM model which in this case is **gpt-4**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0377877c-73f4-4508-9a4f-9ddcd14bea96",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"<Your Azure Endpoint>\"\n",
    "os.environ[\"AZURE_OPENAI_KEY\"] = \"<Your Azure AI Key>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c91f3a-5a72-463c-b869-a970ae1139df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import AzureOpenAI\n",
    "    \n",
    "client = AzureOpenAI(\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_KEY\"),  \n",
    "    api_version=\"2023-05-15\",\n",
    "    azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa799c1-f587-4c9b-b1bc-7bc37415ca12",
   "metadata": {},
   "source": [
    "### Create Azure AI Search Service"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8b68e1-2488-41d1-be51-436cb47e5c86",
   "metadata": {},
   "source": [
    "Enter in the name you would like for your AI Search service and index along with the name of your resource group and the location you would like your index to be held in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711cbd23-73ab-4ce0-b499-0f254549a7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "service_name='<Your Service Name>'\n",
    "index_name = '<Your Index Name>'\n",
    "location = 'eastus2'\n",
    "resource_group = '<Your Resource Group>'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d9a98f-4772-48ea-acef-0f1e947685e4",
   "metadata": {},
   "source": [
    "Authenticate to use Azure cli, follow the outputs instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ab007c-5c88-4206-aa51-318fc3e82292",
   "metadata": {},
   "outputs": [],
   "source": [
    "! az login"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a076aa-d2c1-4709-aec2-9532e6457e48",
   "metadata": {},
   "source": [
    "Create your Azure AI Search service. We will be using the free tier that holds 50MB of memory and allows you to create up to 3 indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4f5c0e-3fb6-4f79-aaf4-a8f9920af590",
   "metadata": {},
   "outputs": [],
   "source": [
    "! az search service create --name {service_name} --sku free --location {location} --resource-group {resource_group} --partition-count 1 --replica-count 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94fd109a-2729-47b3-9327-811e2ce598b9",
   "metadata": {},
   "source": [
    "Save the key to a JSON file and then we will save the value to our **search_key** variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6b4dee-0ea2-434e-b98f-55d22e871f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "! az search admin-key show --resource-group {resource_group} --service-name {service_name} > keys.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c98d31-ebad-4e66-adef-abcbe222f317",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('keys.json', mode='r') as f:\n",
    "    data = json.load(f)\n",
    "search_key = data[\"primaryKey\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4cc7e03-d080-4486-9e0d-30167fec715a",
   "metadata": {},
   "source": [
    "### Create Azure AI Index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9f88db-a05a-499a-891b-be32ec44cd97",
   "metadata": {},
   "source": [
    "Import the necessary tools to create our index and the fields this will be our **vector store**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094c737d-d941-4681-ac78-e499f9b96805",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents.indexes import SearchIndexClient, SearchIndexerClient\n",
    "from azure.search.documents.indexes.models import (\n",
    "    SimpleField,\n",
    "    SearchField,\n",
    "    SearchableField,\n",
    "    SearchFieldDataType,\n",
    "    SearchIndexerDataContainer,\n",
    "    SearchIndexerDataSourceConnection,\n",
    "    SearchIndex,\n",
    "    SearchIndexer,\n",
    "    TextWeights,\n",
    "    VectorSearch,\n",
    "    VectorSearchProfile,\n",
    "    HnswAlgorithmConfiguration,\n",
    "    ComplexField\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e836161-1910-411a-8dfa-7820c0fc9bd0",
   "metadata": {},
   "source": [
    "Create your index client to pass on information about our index too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e780b6-a045-4779-876a-2b36e4dc5225",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = \"https://{}.search.windows.net/\".format(service_name)\n",
    "index_client = SearchIndexClient(endpoint, AzureKeyCredential(index_key))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defec19a-0a82-413d-9a6b-13b9db5873b7",
   "metadata": {},
   "source": [
    "Next you will add in the field names to the index which are based on the names of your columns. Notice that the **Key** is our 'ID' column and it is a string also that even columns that hold integers will also be strings because we want to be able to search and retrieve data from our index which can only be done so if our data is in string format.\n",
    "\n",
    "If you **added embeddings** to your data skip to the next section [Adding Embeddings to Vector Store](#Embeddings-to-Vector-Store)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a949a7ec-6a28-43ed-b16a-0245836a187f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = [\n",
    "    SimpleField(\n",
    "        name=\"ID\",\n",
    "        type=SearchFieldDataType.String,\n",
    "        key=True,\n",
    "    ),\n",
    "    SearchableField(\n",
    "        name=\"work_year\",\n",
    "        type=SearchFieldDataType.String,\n",
    "        searchable=True,\n",
    "    ),\n",
    "    SearchableField(\n",
    "        name=\"experience_level\",\n",
    "        type=SearchFieldDataType.String,\n",
    "        searchable=True,\n",
    "    ),    \n",
    "    SearchableField(\n",
    "        name=\"employment_type\",\n",
    "        type=SearchFieldDataType.String,\n",
    "        searchable=True,\n",
    "    ),\n",
    "    SearchableField(\n",
    "        name=\"job_title\",\n",
    "        type=SearchFieldDataType.String,\n",
    "        searchable=True,\n",
    "    ),\n",
    "    SearchableField(\n",
    "        name=\"salary\",\n",
    "        type=SearchFieldDataType.String,\n",
    "        searchable=True,\n",
    "    ),\n",
    "    SearchableField(\n",
    "        name=\"salary_currency\",\n",
    "        type=SearchFieldDataType.String,\n",
    "        searchable=True,\n",
    "    ),\n",
    "    SearchableField(\n",
    "        name=\"salary_in_usd\",\n",
    "        type=SearchFieldDataType.String,\n",
    "        searchable=True,\n",
    "    ),\n",
    "    SearchableField(\n",
    "        name=\"employee_residence\",\n",
    "        type=SearchFieldDataType.String,\n",
    "        searchable=True,\n",
    "    ),\n",
    "    SearchableField(\n",
    "        name=\"remote_ratio\",\n",
    "        type=SearchFieldDataType.String,\n",
    "        searchable=True,\n",
    "    ),\n",
    "    SearchableField(\n",
    "        name=\"company_location\",\n",
    "        type=SearchFieldDataType.String,\n",
    "        searchable=True,\n",
    "    ),\n",
    "    SearchableField(\n",
    "        name=\"company_size\",\n",
    "        type=SearchFieldDataType.String,\n",
    "        searchable=True,\n",
    "    )\n",
    "]\n",
    "    \n",
    "#set our index values\n",
    "index = SearchIndex(name=index_name, fields=fields)\n",
    "#create our index\n",
    "index_client.create_index(index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c113a3-3b95-4359-b307-73dda33d5394",
   "metadata": {},
   "source": [
    "<a id='Embeddings-to-Vector-Store'> <h4>Optional: Adding Embeddings to Vector Store</h4> </a> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361e905c-a945-427f-ac03-741ff6bb54be",
   "metadata": {},
   "source": [
    "If you are working with embeddings you need to add a **SearchField** that holds a collection which is your array of numerical values. The name of the column is the same as our dataset **job_title_vector**. We also need to set a **vector profile** which dictates what algorithm we will have our vector store use to find text that are similar to each other (find the nearest neighbors) for this profile we will be using the **Hierarchical Navigable Small World (HNSW) algorithm**, we have named our profile **vector_search**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8107360d-a4f2-4b55-9fe0-8cf8ea3c618a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = [\n",
    "    fields = [\n",
    "    SimpleField(\n",
    "        name=\"ID\",\n",
    "        type=SearchFieldDataType.String,\n",
    "        key=True,\n",
    "    ),\n",
    "    SearchableField(\n",
    "        name=\"work_year\",\n",
    "        type=SearchFieldDataType.String,\n",
    "        searchable=True,\n",
    "    ),\n",
    "    SearchableField(\n",
    "        name=\"experience_level\",\n",
    "        type=SearchFieldDataType.String,\n",
    "        searchable=True,\n",
    "    ),    \n",
    "    SearchableField(\n",
    "        name=\"employment_type\",\n",
    "        type=SearchFieldDataType.String,\n",
    "        searchable=True,\n",
    "    ),\n",
    "    SearchableField(\n",
    "        name=\"job_title\",\n",
    "        type=SearchFieldDataType.String,\n",
    "        searchable=True,\n",
    "    ),\n",
    "    SearchField(\n",
    "        name=\"job_title_vector\",\n",
    "        type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "        searchable=True,\n",
    "        vector_search_dimensions=len(generate_embeddings(\"Text\")),\n",
    "        vector_search_profile_name=\"my-vector-config\"\n",
    "    ),\n",
    "    SearchableField(\n",
    "        name=\"salary\",\n",
    "        type=SearchFieldDataType.String,\n",
    "        searchable=True,\n",
    "    ),\n",
    "    SearchableField(\n",
    "        name=\"salary_currency\",\n",
    "        type=SearchFieldDataType.String,\n",
    "        searchable=True,\n",
    "    ),\n",
    "    SearchableField(\n",
    "        name=\"salary_in_usd\",\n",
    "        type=SearchFieldDataType.String,\n",
    "        searchable=True,\n",
    "    ),\n",
    "    SearchableField(\n",
    "        name=\"employee_residence\",\n",
    "        type=SearchFieldDataType.String,\n",
    "        searchable=True,\n",
    "    ),\n",
    "    SearchableField(\n",
    "        name=\"remote_ratio\",\n",
    "        type=SearchFieldDataType.String,\n",
    "        searchable=True,\n",
    "    ),\n",
    "    SearchableField(\n",
    "        name=\"company_location\",\n",
    "        type=SearchFieldDataType.String,\n",
    "        searchable=True,\n",
    "    ),\n",
    "    SearchableField(\n",
    "        name=\"company_size\",\n",
    "        type=SearchFieldDataType.String,\n",
    "        searchable=True,\n",
    "    )\n",
    "]\n",
    "\n",
    "vector_search = VectorSearch(\n",
    "    profiles=[VectorSearchProfile(name=\"my-vector-config\", algorithm_configuration_name=\"my-algorithms-config\")],\n",
    "    algorithms=[HnswAlgorithmConfiguration(name=\"my-algorithms-config\")],\n",
    ")\n",
    "   \n",
    "#set our index values\n",
    "index = SearchIndex(name=index_name, fields=fields, vector_search=vector_search)\n",
    "#create our index\n",
    "index_client.create_index(index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ed728d-2af3-42d5-843c-e94266ce66d1",
   "metadata": {},
   "source": [
    "### Upload Data to our Index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65aece2-ad33-4600-b862-a1eedd2cf50a",
   "metadata": {},
   "source": [
    "Here we are creating a **search client** that will allow us to upload our data to our index and query our index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3273fd-748e-41ee-ad42-6af31db93855",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents import SearchClient\n",
    "search_client = SearchClient(endpoint, index_name, AzureKeyCredential(index_key))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2dd96f4-439e-4c74-877e-6da7b10331ff",
   "metadata": {},
   "source": [
    "Next we will convert our dataset into a JSON object because even though it is in JSON format its still labeled as a Python object. After that we will upload each row of our data, or in this case, since we are now dealing with JSON, each group as a separate document. This process is essentially **chunking** our data to help our index easily query our data and only retrieve the groups that hold similar text to the our query. This also minimizes hallucinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d151e32a-ad57-4cf4-9928-8f8933e98959",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    " \n",
    "# Convert JSON data to a Python object\n",
    "data = json.loads(df_json)\n",
    "\n",
    "# Iterate through the JSON array\n",
    "for item in data:\n",
    "    result = search_client.upload_documents(documents=[item])\n",
    "\n",
    "print(\"Upload of new document succeeded: {}\".format(result[0].succeeded))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc10ce7e-e9da-443e-9cd1-7cad4faa740b",
   "metadata": {},
   "source": [
    "### Interacting with our Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9630cd3-98ab-456f-8e3e-095ce6982143",
   "metadata": {},
   "source": [
    "First, we will write our query. You can run any of the ones below or make your own. That query will be passed to our index which will then give us results of documents that held similar text to our query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f13c6e1-c719-4fae-a097-f6d7f5081caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Please count how many ML Engineers are there.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcf66f5-a0e1-4b9b-9b55-532b9ead433a",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Please list the unique job titles.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34af7401-4c24-4e5f-888a-990e72e82afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Please count how many employees worked in 2020.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011eedb0-663e-4e4b-9304-f2a810ad5992",
   "metadata": {},
   "source": [
    "Here is where we will input our query and then fix the formatting of the results in a way that our model can understand. This will mean first gathering our results in a list, removing any unncessary keys to lessen the token count, converting that list into JSON format so that it is also a string, and then adding quotes around spaces for the model to better decipher our query results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e34ae18-89f3-40f6-96c6-25b9b1ec5c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gathering our query results\n",
    "search_results = list(search_client.search(query))\n",
    "\n",
    "#removing any removing any unncessary keys to lessen the token count (some of these are provided by the vector store)\n",
    "#job_title_vector is for users that included embeddings to their data\n",
    "remove_keys = ['job_title_vector', '@search.reranker_score', '@search.highlights', '@search.captions', '@search.score']\n",
    "for l in search_results:\n",
    "    for i in remove_keys:\n",
    "        l.pop(i, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35dfd1c-06ed-47cf-b6d7-bb6368ff203b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting that list into JSON format\n",
    "search_results = json.dumps(search_results)\n",
    "#adding quotes around spaces\n",
    "context=' '.join('\"{}\"'.format(word) for word in search_results.split(' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a6d875-4ce3-4a0d-a803-d65eebb17821",
   "metadata": {},
   "source": [
    "We will then pass our context and query to our model via a message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ff5e34-c60f-4e99-a3f3-29950c6e617b",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant who answers only from the given Context and answers the question from the given Query. If you are asked to count then you must count all of the occurances mentioned.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Context: \"+ context + \"\\n\\n Query: \" + query}\n",
    "    ],\n",
    "    #max_tokens=100,\n",
    "    temperature=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf1549d-fea7-4a37-b94c-269724c7c519",
   "metadata": {},
   "source": [
    "Now we can see our results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1541aa6e-e09c-4151-9938-c42c063e6dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c915c9",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "Here we created embeddings from structured data and fed these embeddings to our LLM. Key skills you learned were to : \n",
    "+ Create embeddings and a vector store using Azure AI Search\n",
    "+ Send prompts to the LLM grounded on your structured data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0459e0ae-5183-4b6a-9eca-41c97b0b8a8c",
   "metadata": {},
   "source": [
    "## Clean up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb500e2-c8cb-428c-85f7-d4886d89899d",
   "metadata": {},
   "source": [
    "**Warning:** Dont forget to delete the resources we just made to avoid accruing additional costs, including shutting down your Azure ML compute, delete your AI search resource, and optionally delete your deployed models in AI Studio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0e5690-1e15-4c97-9422-410c54a92f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete search service this will also delete any indexes\n",
    "! az search service delete --name {service_name} --resource-group {resource_group} -y"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}

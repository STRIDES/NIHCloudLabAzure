{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Embedding and Indexing with Azure OpenAI and AI Search\n",
    "\n",
    "## Overview \n",
    "This tutorial provides a step-by-step guide on how to pull files from [Azure Blob Storage](https://learn.microsoft.com/en-us/azure/storage/blobs/storage-blobs-introduction), generate embeddings for these files, and store the embeddings in an [Azure AI Search](https://learn.microsoft.com/en-us/azure/search/search-what-is-azure-search) index. Embeddings are numerical representations of text that capture the semantic meaning of the content, facilitating advanced search and analysis. An index in AI search is a data structure that organizes these embeddings to improve the speed and efficiency of search queries. Additionally, this tutorial demonstrates how to enable users to interact with these embedding indexes through Azure AI Search and [Azure OpenAI](https://learn.microsoft.com/en-us/azure/ai-services/openai/overview), effectively allowing them to chat over the original files from Azure Blob Storage.\n",
    "### Learning Objectives  \n",
    "1. **Vectorization**:\n",
    "    - Learn how to extract files from Azure Blob Storage.\n",
    "    - Understand how to generate embeddings using Azure OpenAI.\n",
    "    - Discover how to store documents with custom metadata in an Azure AI Index.\n",
    "2. **Retrieval**:\n",
    "    - Gain skills in interacting with Azure AI Search indexes using Azure OpenAI.\n",
    "\n",
    "Each section of this notebook will guide you through specific tasks and demonstrate how to utilize the REST APIs provided by each Azure service. By the end of this notebook, you will have a comprehensive understanding of how to integrate and utilize these Azure services to develop a robust data processing and retrieval application. \n",
    "### Prerequisites  \n",
    "Before proceeding with this notebook, please ensure that you have the following Azure services deployed and configured. Resources can be deployed manually in Azure portal or automated by following along with the [ARM Deployment tutorial](../azure_infra_setup/README.md):  \n",
    "  \n",
    "1. **Azure OpenAI Service**:   \n",
    "    - Ensure that you have deployed both a GPT model and an Ada model within your Azure OpenAI instance.\n",
    "    - Estimated costs for this service varies based on the model usage and number of API calls.\n",
    "        - **gpt-4o-mini(2024-07-18):** \\\\$0.15 input/ \\\\$0.60 output per 1M tokens\n",
    "        - **text-embedding-3-small(1):** $0.00002 per 1K tokens\n",
    "        \n",
    "2. **Azure AI Search**:   \n",
    "    - Your Azure AI Search service should be a minimum of the Basic tier to ensure compatibility with Azure OpenAI.  \n",
    "    - **Estimated cost for this service is $0.10 per hour.**\n",
    "    \n",
    "3. **Azure Blob Storage Account**:   \n",
    "    - You should have an Azure Blob Storage account with PDF files stored in a blob container. These files should be located in the `/search_documents` directory of the `GenAI` directory.  \n",
    "    - **Estimated cost for this service is $0.018 per GB.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Started \n",
    "\n",
    "### 0. Environment Setup  \n",
    "This section will guide you through setting up the environment for the notebook. We will import the necessary libraries, load environment variables, and configure Azure AI Search parameters.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1 Install Python libraries from requirements.txt\n",
    "\n",
    "To ensure all necessary Python libraries are installed in the virtual environment for this notebook, we will use `pip` to install the packages specified in the `requirements.txt` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install -r ../requirements.txt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2 Import Necessary Libraries  \n",
    "Import all the packages installed in the virtual environment into our Python script. This is a crucial step as it makes the required functionalities available for the script to execute correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries  \n",
    "  \n",
    "# For handling file and directory operations  \n",
    "import os  \n",
    "  \n",
    "# For handling I/O operations  \n",
    "import io  \n",
    "  \n",
    "# For extracting text and tables from PDF files  \n",
    "import pdfplumber  \n",
    "  \n",
    "# For interacting with Azure Blob Storage  \n",
    "from azure.storage.blob import BlobServiceClient  \n",
    "  \n",
    "# For handling Azure credentials  \n",
    "from azure.core.credentials import AzureKeyCredential  \n",
    "from azure.identity import DefaultAzureCredential  \n",
    "  \n",
    "# For working with Azure Search service  \n",
    "from azure.search.documents import SearchClient  \n",
    "from azure.search.documents.indexes import SearchIndexClient  \n",
    "  \n",
    "# For configuring search indexes and fields  \n",
    "from azure.search.documents.indexes.models import (  \n",
    "    SimpleField,                   # Represents a simple field in an index  \n",
    "    SearchFieldDataType,           # Represents the data type of a field  \n",
    "    VectorSearch,                  # Enables vector search capabilities  \n",
    "    SearchIndex,                   # Represents a search index  \n",
    "    SearchableField,               # Represents a searchable field  \n",
    "    SearchField,                   # Represents a field in a search index  \n",
    "    VectorSearchProfile,           # Represents a vector search profile  \n",
    "    HnswAlgorithmConfiguration     # Configuration for HNSW algorithm in vector search  \n",
    ")  \n",
    "  \n",
    "# For loading environment variables from a .env file  \n",
    "from dotenv import load_dotenv  \n",
    "  \n",
    "# For utilizing OpenAI functionalities within Azure  \n",
    "from openai import AzureOpenAI  \n",
    "  \n",
    "# For tokenization tasks  \n",
    "import tiktoken  \n",
    "  \n",
    "# For regular expression operations  \n",
    "import re  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.3 Load Environment Variables  \n",
    "Load the environment variables from a `.env` file. Ensure you have a `.env` file with the required Azure service credentials and configurations. This file should contain all necessary keys and connection strings to connect to your Azure services.\n",
    "\n",
    "Resources can be deployed manually in Azure portal or automated by following along with the [ARM Deployment tutorial](../azure_infra_setup/README.md). This will also go through creating your .env file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "env_path = '../azure_infra_setup/.env'\n",
    "load_dotenv(dotenv_path=env_path) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you did not run the ARM Deployment tutorial create a .env file and enter in the following information:\n",
    "  \n",
    "```  \n",
    "# Example .env file format:  \n",
    "AZURE_OPENAI_VERSION=your_openai_version  \n",
    "AZURE_OPENAI_BASE=your_openai_base_url  \n",
    "AZURE_OPENAI_ENDPOINT=your_openai_endpoint  \n",
    "AZURE_OPENAI_KEY=your_openai_key  \n",
    "AZURE_GPT_DEPLOYMENT=your_gpt_deployment  \n",
    "AZURE_EMBEDDINGS_DEPLOYMENT=your_embeddings_deployment  \n",
    "AZURE_SEARCH_ENDPOINT=your_search_endpoint  \n",
    "AZURE_SEARCH_ADMIN_KEY=your_search_admin_key  \n",
    "AZURE_SEARCH_INDEX=your_search_index  \n",
    "BLOB_CONTAINER_NAME=your_blob_container_name  \n",
    "BLOB_CONNECTION_STRING=your_blob_connection_string  \n",
    "BLOB_ACCOUNT_NAME=your_blob_account_name \n",
    "```\n",
    "\n",
    "Then run `load_dotenv(dotenv_path=env_path)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The `load_dotenv()` function reads the key-value pairs from the .env file and adds them to the environment variables.\n",
    "- Replace the placeholder values in your .env file with your actual Azure service credentials and configuration details.\n",
    "- ***This step is crucial for securely managing your credentials and keeping them out of your main codebase.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.4 Configure Azure AI Search Parameters\n",
    "Configure the Azure AI Search parameters using the loaded environment variables. This allows us to set up the necessary configurations for connecting to the Azure AI Search service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Configure Azure AI Search parameters  \n",
    "search_endpoint = os.getenv('AZURE_SEARCH_SERVICE_ENDPOINT')  # Get the Azure Search endpoint from environment variables  \n",
    "search_key = os.getenv('AZURE_SEARCH_API_KEY') # Get the Azure Search admin key from environment variables  \n",
    "credentials = AzureKeyCredential(search_key) #Set up Auzure credentials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `os.getenv('AZURE_SEARCH_SERVICE_ENDPOINT')` retrieves the value of the AZURE_SEARCH_ENDPOINT environment variable, which contains the endpoint URL for your Azure Search service.\n",
    "- `os.getenv('AZURE_SEARCH_API_KEY')` retrieves the value of the AZURE_SEARCH_ADMIN_KEY environment variable, which contains the admin key for your Azure Search service.\n",
    "- These configurations are essential for authenticating and connecting to your Azure Search service."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Vectorization \n",
    "  \n",
    "In this section, we will connect to Azure Blob Storage, process PDF documents into text chunks with metadata, generate embeddings using Azure OpenAI, and upload the data to Azure AI Search.  \n",
    "\n",
    "Objectives:\n",
    "1. Setup Function for Azure OpenAI\n",
    "2. Connecting to Azure Blob Storage\n",
    "3. Splitting Text with Metadata\n",
    "4. Loading Blob Content\n",
    "5. Vectorize Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Setup Function for Azure OpenAI  \n",
    "This function sets up the Azure OpenAI instance using the provided API key, version, and endpoint from environment variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def setup_azure_openai():  \n",
    "    \"\"\"  \n",
    "    Sets up Azure OpenAI.  \n",
    "    \"\"\"  \n",
    "    print(\"Setting up Azure OpenAI...\")  \n",
    "    azure_openai = AzureOpenAI(  \n",
    "        api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),  \n",
    "        api_version= \"2024-05-01-preview\", #os.getenv('AZURE_OPENAI_VERSION'),  \n",
    "        azure_endpoint=os.getenv('AZURE_OPENAI_ENDPOINT')  \n",
    "    )  \n",
    "    print(\"Azure OpenAI setup complete.\")  \n",
    "    return azure_openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Connecting to Azure Blob Storage  \n",
    "The following function connects to the Azure Blob Storage using the provided connection string and container name from the environment variables.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def connect_to_blob_storage():  \n",
    "    \"\"\"  \n",
    "    Connects to Azure Blob Storage.  \n",
    "    \"\"\"  \n",
    "    print(\"Connecting to Blob Storage...\")  \n",
    "    blob_service_client = BlobServiceClient.from_connection_string(os.getenv(\"BLOB_CONNECTION_STRING\"))  \n",
    "    container_client = blob_service_client.get_container_client(os.getenv(\"BLOB_CONTAINER_NAME\"))  \n",
    "    print(\"Connected to Blob Storage.\")  \n",
    "    return container_client "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Splitting Text with Metadata  \n",
    "Split the content from PDF files into chunks with associated metadata. The text will be split by a max token length with additional chunk overlap. This is useful for processing large documents.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def split_text_with_metadata(text, metadata, max_length=800, overlap=75, encoding_name='cl100k_base'):  \n",
    "    \"\"\"  \n",
    "    Splits the text into chunks with metadata.  \n",
    "    \"\"\"  \n",
    "    tokenizer = tiktoken.get_encoding(encoding_name)  \n",
    "    tokens = tokenizer.encode(text)  \n",
    "    chunks = []  \n",
    "    start = 0  \n",
    "    end = max_length  \n",
    "      \n",
    "    while start < len(tokens):  \n",
    "        chunk = tokens[start:end]  \n",
    "        chunk_text = tokenizer.decode(chunk)  \n",
    "        chunk_metadata = metadata.copy()  \n",
    "        chunk_metadata.update({  \n",
    "            'start_token': start,  \n",
    "            'end_token': end,  \n",
    "            'chunk_length': len(chunk),  \n",
    "            'chunk_text_preview': chunk_text[:50] + '...'  \n",
    "        })  \n",
    "        chunks.append({  \n",
    "            'text': chunk_text,  \n",
    "            'metadata': chunk_metadata  \n",
    "        })  \n",
    "        start = end - overlap  \n",
    "        end = start + max_length  \n",
    "      \n",
    "    return chunks  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. ***Tokenize Text***: The text is encoded into tokens using the tokenizer.\n",
    "2. ***Initialize Variables***: Set up initial indices for chunking.\n",
    "3. ***Create Chunks***: Loop through the tokens to create chunks:\n",
    "    - Extract a chunk of tokens.\n",
    "    - Decode the chunk back into text.\n",
    "    - Copy and update metadata with chunk-specific information.\n",
    "    - Append the chunk and its metadata to the list.\n",
    "4. ***Overlap Handling***: Move the start index back by the overlap amount to ensure chunks overlap as specified.\n",
    "\n",
    "**Key Params**:\n",
    "- ***Max Chunk Size (max_length)***: Each chunk will have a maximum of `max_length` tokens (default is 800 tokens).\n",
    "- ***Chunk Overlap (overlap)***: Consecutive chunks will overlap by `overlap` tokens (default is 75 tokens)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Loading Blob Content  \n",
    "Load and extracts the content of a PDF file from the Azure Blob Storage client.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Check File Type**:\n",
    "    - The function first checks if the blob is a PDF file by verifying the file extension.\n",
    "    - If the file is not a PDF, it raises a `ValueError`.\n",
    "2. **Download Blob Content**:\n",
    "    - The blob content is downloaded and read into `blob_data`.\n",
    "3. **Convert to Stream**:\n",
    "    - The blob data is converted into a byte stream using `io.BytesIO`.\n",
    "4. **Extract Text from PDF**:\n",
    "    - The PDF is opened using `pdfplumber`.\n",
    "    - Text is extracted from each page of the PDF and concatenated into `document_text`.\n",
    "5. **Return Document Text**:\n",
    "    - The function returns the extracted text from the PDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_blob_content(blob_client):  \n",
    "    \"\"\"  \n",
    "    Loads and returns the content of the PDF blob.  \n",
    "    \"\"\"  \n",
    "    blob_name = blob_client.blob_name  \n",
    "    if not blob_name.lower().endswith('.pdf'):  \n",
    "        raise ValueError(f\"Blob {blob_name} is not a PDF file.\")  \n",
    "      \n",
    "    blob_data = blob_client.download_blob().readall()  \n",
    "    pdf_stream = io.BytesIO(blob_data)  \n",
    "    document_text = \"\"  \n",
    "      \n",
    "    with pdfplumber.open(pdf_stream) as pdf:  \n",
    "        for page in pdf.pages:  \n",
    "            document_text += page.extract_text() + \"\\n\"  \n",
    "      \n",
    "    return document_text  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Vectorize Workflow  \n",
    "Uses multiple functions to orchestrate the vector workflow. This workflow will connect to Azure services, processes blobs, generate embeddings, and upload the data to Azure AI Search index.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up container and Azure OpenAi clients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "container_client = connect_to_blob_storage()\n",
    "azure_openai = setup_azure_openai() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5.0 Chunking the data\n",
    "\n",
    "The `chunk_data` function is responsible for reading PDF files from Azure Blob Storage and splits their content into smaller chunks with metadata. It performs the following tasks:\n",
    "\n",
    "1. **Connects to Azure Blob Storage:** It uses `connect_to_blob_storage()` to establish a connection to a blob storage container.\n",
    "2. **Lists Blobs in the Container:** It retrieves a list of all blobs (files) in the container using `container_client.list_blobs()`.\n",
    "3. **Processes Only PDF Files:** It iterates through the blobs and skips any files that are not PDFs (based on their file extension).\n",
    "4. **Loads and Processes PDF Content:** For each PDF file it retrieves the blob's content using `load_blob_content(blob_client)`. It generates a public link to the blob using the storage account and container name from environment variables.\n",
    "5. **Adds Metadata and Splits Content:** It creates metadata for the blob (e.g., blob name and document link). It splits the PDF content into smaller chunks along with the metadata using `split_text_with_metadata()`.\n",
    "6. **Handles Errors:** If any blob fails to process, it logs the error and continues with the next blob.\n",
    "7. **Returns Chunked Documents:** The function collects all the processed chunks into a `documents` list and prints a message when processing is complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_data():  \n",
    "    \"\"\"  \n",
    "    Function will read and chunk PDF documents in blob storage with metadata.  \n",
    "    \"\"\"  \n",
    "        \n",
    "    print(\"Listing blobs in container...\")  \n",
    "    blob_list = container_client.list_blobs()  \n",
    "    documents = []  \n",
    "    for blob in blob_list:  \n",
    "        if not blob.name.lower().endswith('.pdf'):  \n",
    "            print(f\"Skipping non-PDF blob: {blob.name}\")  \n",
    "            continue  \n",
    "          \n",
    "        print(f\"Processing blob: {blob.name}\")  \n",
    "        blob_client = container_client.get_blob_client(blob)  \n",
    "        try:  \n",
    "            document = load_blob_content(blob_client)  \n",
    "            document_link = f'https://{os.getenv(\"BLOB_ACCOUNT_NAME\")}.blob.core.windows.net/{os.getenv(\"BLOB_CONTAINER_NAME\")}/{blob.name}'  \n",
    "              \n",
    "            metadata = {\"blob_name\": blob.name, \"document_link\": document_link}  \n",
    "            chunks = split_text_with_metadata(document, metadata)  \n",
    "            documents.extend(chunks)  \n",
    "        except Exception as e:  \n",
    "            print(f\"Failed to process blob {blob.name}: {e}\")  \n",
    "      \n",
    "    print(\"Blobs processed and documents chunked.\")\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5.1 Adding Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `embeddings` function is responsible for generating vector embeddings for chunks of text using Azure OpenAI's embedding API. It performs the following tasks:\n",
    "\n",
    "1. **Sets Up Tokenizer and Token Limit:** Uses the `tiktoken` library to get a tokenizer (`cl100k_base`) for encoding text into tokens. Defines a maximum token limit (`max_tokens = 8192`) to ensure chunks do not exceed the model's input size.\n",
    "2. **Processes Document Chunks:** Iterates through a list of documents (assumed to be preprocessed chunks of text with metadata). For each chunk it prints the chunk's text and its position in the list.\n",
    "3. **Checks Token Limit:**: Encodes the chunk's text into tokens using the tokenizer. Skips the chunk if the number of tokens exceeds the `max_tokens` limit, logging a message.\n",
    "4. **Generates Embeddings:** Sends the chunk's text to Azure OpenAI's embedding API (`azure_openai.embeddings.create`) using the model specified in the environment variable `AZURE_EMBEDDINGS_DEPLOYMENT`. Extracts the embedding vector from the API response and pairs it with the chunk's metadata.\n",
    "5. **Stores Embeddings:** Appends the embedding and its associated metadata to the `embeddings` list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embeddings(documents):\n",
    "    \"\"\"  \n",
    "    Function will generate embeddings.  \n",
    "    \"\"\"   \n",
    "    print(\"Generating embeddings...\")  \n",
    "    embeddings = []  \n",
    "    tokenizer = tiktoken.get_encoding(\"cl100k_base\")  \n",
    "    max_tokens = 8192  \n",
    "    for i, doc in enumerate(documents):  \n",
    "        #print(f\"Processing chunk {i + 1}/{len(documents)}\")  \n",
    "        #print(f\"Chunk text: {doc['text']}\\n\")  \n",
    "        tokens = tokenizer.encode(doc[\"text\"])  \n",
    "        if len(tokens) > max_tokens:  \n",
    "            print(f\"Skipping document chunk {i + 1} with {len(tokens)} tokens, exceeding max limit of {max_tokens}.\")  \n",
    "            continue  \n",
    "        response = azure_openai.embeddings.create(input=doc[\"text\"], model=os.getenv('AZURE_EMBEDDINGS_DEPLOYMENT'))\n",
    "        \n",
    "        embeddings.append({  \n",
    "            \"embedding\": response.data[0].embedding,  \n",
    "            \"metadata\": doc[\"metadata\"]  \n",
    "        })  \n",
    "        #print(f\"Embeddings: {response.data[0].embedding}\")  \n",
    "    print(\"Embeddings generation complete.\")  \n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5.2 Creating a Search Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `search_index` function is responsible for creating and configuring an Azure Cognitive Search index and populating it with the necessary fields and vector search capabilities. \n",
    "\n",
    "1. **Initialize Azure Search Client:** Retrieves the Azure Search admin key and endpoint from environment variables (`AZURE_SEARCH_ADMIN_KEY` and `AZURE_SEARCH_ENDPOINT`). Creates a SearchIndexClient object using the AzureKeyCredential for authentication.\n",
    "2. **Define Index Fields:** Specifies the schema (fields) for the search index:\n",
    "- `id`: A unique identifier for each document (key field).\n",
    "- `content`: A searchable field for the document's text content.\n",
    "- `blob_name`: A searchable field for the name of the blob in Azure Blob Storage.\n",
    "- `document_link`: A searchable field for the document's URL or link.\n",
    "- `embedding`: A vector field for storing embeddings (used for semantic search). It includes:\n",
    "- `vector_search_dimensions=1536`: Specifies the dimensionality of the embedding vectors.\n",
    "- `vector_search_profile_name=\"myHnswProfile\"`: Links the field to a vector search profile.\n",
    "3. **Configure Vector Search:** Sets up vector search capabilities using the Hierarchical Navigable Small World (HNSW) algorithm:\n",
    "- `HnswAlgorithmConfiguration`: Configures the HNSW algorithm for vector search.\n",
    "- `VectorSearchProfile`: Associates the algorithm configuration with a profile (`myHnswProfile`).\n",
    "4. **Create the Search Index:** Combines the fields and vector search configuration into a SearchIndex object. Creates the index in Azure Cognitive Search using `search_index_client.create_index(index)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Search Index\n",
    "def search_index():\n",
    "    \"\"\"\n",
    "    Function creates index and populates fields in your Azure Search AI service.\n",
    "    \"\"\"\n",
    "    print(\"Creating search index...\")   \n",
    "    search_index_client = SearchIndexClient(endpoint=search_endpoint, credential=credentials)  \n",
    "    fields = [  \n",
    "        SimpleField(name=\"id\", type=SearchFieldDataType.String, key=True),  \n",
    "        SearchableField(name=\"content\", type=SearchFieldDataType.String),  \n",
    "        SearchableField(name=\"blob_name\", type=SearchFieldDataType.String),  \n",
    "        SearchableField(name=\"document_link\", type=SearchFieldDataType.String),  \n",
    "        SearchField(  \n",
    "            name=\"embedding\",  \n",
    "            type=SearchFieldDataType.Collection(SearchFieldDataType.Single),  \n",
    "            searchable=True,  \n",
    "            vector_search_dimensions=1536,  \n",
    "            vector_search_profile_name=\"myHnswProfile\"  \n",
    "        )  \n",
    "    ]  \n",
    "    vector_search = VectorSearch(  \n",
    "        algorithms=[  \n",
    "            HnswAlgorithmConfiguration(name=\"myHnsw\")  \n",
    "        ],  \n",
    "        profiles=[  \n",
    "            VectorSearchProfile(  \n",
    "                name=\"myHnswProfile\",  \n",
    "                algorithm_configuration_name=\"myHnsw\"  \n",
    "            )  \n",
    "        ]  \n",
    "    )  \n",
    "    index = SearchIndex(name=\"documents-index\", fields=fields, vector_search=vector_search)  \n",
    "    search_index_client.create_index(index)  \n",
    "    print(\"Search index created.\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5.3 Uploading the Data to the Search Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `upload` function is responsible for uploading document chunks and their corresponding embeddings to an Azure Cognitive Search index. Here's a breakdown of what it does:\n",
    "\n",
    "1. **Initialize Azure Search Client:** Creates a `SearchClient` object to interact with the Azure Cognitive Search service.\n",
    "2. **Prepare Documents for Upload:** Iterates over the `embeddings` list (assumed to contain embeddings and metadata for document chunks). For each embedding, it creates a dictionary with the same index fields mentioned above. Appends each prepared document to the documents_to_upload list.\n",
    "3. **Upload Documents to Azure Search:** Uses the `upload_documents` method of the `SearchClient` to upload the prepared documents to the Azure Cognitive Search index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload(embeddings, documents):\n",
    "    \"\"\"\n",
    "    Function will upload chunks and embeddings to Azure AI Search\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Uploading documents to search index...\")  \n",
    "    search_client = SearchClient(endpoint=search_endpoint, index_name=\"documents-index\", credential=credentials)  \n",
    "    documents_to_upload = []  \n",
    "\n",
    "    for i, doc in enumerate(embeddings):  \n",
    "        documents_to_upload.append({  \n",
    "            \"id\": str(i),  \n",
    "            \"content\": documents[i][\"text\"],  \n",
    "            \"embedding\": doc[\"embedding\"],  \n",
    "            \"blob_name\": doc[\"metadata\"][\"blob_name\"],  \n",
    "            \"document_link\": doc[\"metadata\"][\"document_link\"]  \n",
    "        })  \n",
    "    search_client.upload_documents(documents=documents_to_upload)  \n",
    "    print(\"Documents uploaded to search index.\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets put all of our functions together to create our vector workflow!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def vectorize():    \n",
    "    \"\"\"  \n",
    "    Main function that orchestrates the vector workflow.  \n",
    "    \"\"\" \n",
    "    documents = chunk_data()\n",
    "    data_embeddings = embeddings(documents)\n",
    "    search_index()\n",
    "    upload(data_embeddings, documents)\n",
    "    \n",
    "vectorize()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a reminder here is a summary of what this workflow does."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Setup Connections**:\n",
    "    - Connect to Azure OpenAI and Blob Storage.\n",
    "2. **Process Blobs**:\n",
    "    - List blobs in the container.\n",
    "    - For each PDF blob, load its content and split it into chunks with metadata.\n",
    "3. **Customize Metadata**:\n",
    "    - Add custom metadata such as the blob file name and blob URL:\n",
    "        ```python\n",
    "        metadata = {\"blob_name\": blob.name, \"document_link\": document_link}  \n",
    "        ```\n",
    "4. **Generate Embeddings**:\n",
    "    - For each chunk, generate embeddings using Azure OpenAI.\n",
    "5. **Create Search Index**:\n",
    "    - Define and create a search index in Azure AI Search.\n",
    "6. **Upload Documents**:\n",
    "    - Upload the chunks and their embeddings to the search index."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Retrieve \n",
    "\n",
    "In this section, we will implement a function (`chat_on_your_data`) to perform retrieval queries over documents from the Azure AI Search Index using Azure OpenAI for chat capabilities. Our chatbot function will perform retrieval queries over documents from the Azure AI Search Index using Azure OpenAI. Construct a search query, interacts with the search index, and processes the results to provide relevant information based on the query. The steps of the function are detailed below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Configure Azure OpenAI Parameters**:\n",
    "    - Retrieve necessary configurations and API keys from environment variables.\n",
    "2. **Append User Query**:\n",
    "    - Append the user's query to the chat messages list.\n",
    "3. **Initialize AzureOpenAI Client**:\n",
    "    - Initialize the Azure OpenAI client using the provided endpoint, API key, and API version.\n",
    "4. **Create Chat Completion**:\n",
    "    - Create a chat completion request using Azure OpenAI.\n",
    "    - Specify the model deployment, chat messages, and additional parameters like `max_tokens`, `temperature`, etc.\n",
    "    - Provide extra body parameters to include Azure Search as a data source.\n",
    "        - Extra Body Parameters:\n",
    "            - `endpoint`: The Azure Search endpoint.\n",
    "            - `index_name`: The name of the search index.\n",
    "            - `semantic_configuration`: The semantic search configuration.\n",
    "            - `query_type`: Type of query (e.g., `vector_simple_hybrid`).\n",
    "            - `fields_mapping`: Mapping of fields (if any).\n",
    "            - `role_information`: Information about the role of the assistant.\n",
    "            - `filter`: Any filters to apply to the search (if any).\n",
    "            - `strictness`: Level of strictness for the search.\n",
    "            - `top_n_documents`: Number of top documents to retrieve.\n",
    "            - `authentication`: Authentication details (API key).\n",
    "            - `embedding_dependency`: Embedding deployment details.\n",
    "5. **Extract and Clean Response**:\n",
    "    - Extract the response data from the completion result.\n",
    "    - Clean up the AI response by removing unnecessary characters and formatting it properly.\n",
    "    - Extract the citation URL from the response context.\n",
    "6. **Append AI Response**:\n",
    "    - Append the cleaned AI response to the chat messages list.\n",
    "    - Print the final response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_on_your_data(query, search_index):  \n",
    "    \"\"\"  \n",
    "    Perform retrieval queries over documents from the Azure AI Search Index.  \n",
    "    \"\"\"  \n",
    "    # Define the query and other parameters  \n",
    "    \n",
    "    messages = []  \n",
    "  \n",
    "    # Append user query to chat messages  \n",
    "    messages.append({\"role\": \"user\", \"content\": query})  \n",
    "  \n",
    "    print(f\"User: {query}\")  \n",
    "  \n",
    "    print('Processing...')  \n",
    "    \n",
    "    # Create a chat completion with Azure OpenAI  \n",
    "    completion =  azure_openai.chat.completions.create(  \n",
    "        model=os.getenv('AZURE_GPT_DEPLOYMENT'),  \n",
    "        messages=[  \n",
    "            {\"role\": \"system\", \"content\": \"You are an AI assistant that helps people find information. Ensure the Markdown responses are correctly formatted before responding.\"},  \n",
    "            {\"role\": \"user\", \"content\": query}  \n",
    "        ],  \n",
    "        max_tokens=800,  \n",
    "        temperature=0.7,  \n",
    "        top_p=0.95,  \n",
    "        frequency_penalty=0,  \n",
    "        presence_penalty=0,  \n",
    "        stop=None,  \n",
    "        stream=False,  \n",
    "        extra_body={  \n",
    "            \"data_sources\": [{  \n",
    "                \"type\": \"azure_search\",  \n",
    "                \"parameters\": {  \n",
    "                    \"endpoint\": search_endpoint,  \n",
    "                    \"index_name\": search_index,  \n",
    "                    \"semantic_configuration\": \"default\",  \n",
    "                    \"query_type\": \"vector_simple_hybrid\",  \n",
    "                    \"fields_mapping\": {},  \n",
    "                    \"in_scope\": True,  \n",
    "                    \"role_information\": \"You are an AI assistant that helps people find information.\",  \n",
    "                    \"filter\": None,  \n",
    "                    \"strictness\": 3,  \n",
    "                    \"top_n_documents\": 5,  \n",
    "                    \"authentication\": {  \n",
    "                        \"type\": \"api_key\",  \n",
    "                        \"key\": search_key  \n",
    "                    },  \n",
    "                    \"embedding_dependency\": {  \n",
    "                        \"type\": \"deployment_name\",  \n",
    "                        \"deployment_name\": os.getenv('AZURE_EMBEDDINGS_DEPLOYMENT') \n",
    "                    }  \n",
    "                }  \n",
    "            }]  \n",
    "        }  \n",
    "    )  \n",
    "  \n",
    "    # Extract the response data  \n",
    "    response_data = completion.to_dict()  \n",
    "    ai_response = response_data['choices'][0]['message']['content']  \n",
    "    # Clean up the AI response  \n",
    "    ai_response_cleaned = re.sub(r'\\s+\\.$', '.', re.sub(r'\\[doc\\d+\\]', '', ai_response)) \n",
    "    citation = response_data[\"choices\"][0][\"message\"][\"context\"][\"citations\"][0][\"url\"]  \n",
    "    ai_response_final = f\"{ai_response_cleaned}\\n\\nCitation(s):\\n{citation}\"  \n",
    "  \n",
    "    # Append AI response to chat messages  \n",
    "    messages.append({\"role\": \"assistant\", \"content\": ai_response_final})  \n",
    "  \n",
    "    print(f\"GPT Response: {ai_response_final}\")  \n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now before we run our function we must define Query and search index:\n",
    "- Set up the user query and the name of the search index to be created.\n",
    "- Default values are provided:\n",
    "    - Example query: `\"What year was the New York State Route 373 built?\"`\n",
    "    - Search index: `\"documents-index\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = \"What year was New York State Route 373 built?\" # Example query\n",
    "search_index = \"documents-index\"  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally lets run our function!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Call the function to test it  \n",
    "chat_on_your_data(query, search_index) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Congratulations! You have successfully created a Retrieval-Augmented Generation (RAG) application for documents stored in your Azure Blob Storage Account, using Azure OpenAI and Azure AI Search. At this point, you should have a solid understanding of how to build the logic for vectorizing documents from an Azure Blob Storage container and retrieving those documents in your Azure OpenAI application.\n",
    "\n",
    "### Key Accomplishments:\n",
    "1. **Environment Setup**:\n",
    "    - Initialized Azure OpenAI with the necessary API credentials and configurations.\n",
    "    - Established a connection to Azure Blob Storage to access PDF documents.\n",
    "2. **Vectorize**:\n",
    "    - Implemented a function to split PDF text into manageable chunks with associated metadata.\n",
    "    - Orchestrated the entire vectorization process:\n",
    "        - Setup Azure OpenAI and connected to Azure Blob Storage.\n",
    "        - Retrieved and chunked documents.\n",
    "        - Generated embeddings for each chunk using Azure OpenAI.\n",
    "        - Created a search index in Azure AI Search.\n",
    "        - Uploaded the chunks and their embeddings to Azure AI Search.\n",
    "3. **Retrieve**:\n",
    "    - Implemented a function to perform retrieval queries over the documents indexed in Azure AI Search using Azure OpenAI.\n",
    "    - Executed a user query and performed a search using Azure AI Search.\n",
    "    - Generated a chat completion based on the search results and formatted it for display."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Up\n",
    "Make sure to shut down your Azure ML compute and if desired you can delete your Azure AI Search service, Azure Blob Storage Account, and Azure OpenAI service. ***Note these services can be used in other tutorials in this notebook.***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 - SDK v2",
   "language": "python",
   "name": "python310-sdkv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
